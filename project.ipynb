{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7de26f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c32a752e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Ensure GPU is being used\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"✅ GPU detected: {gpus}\")\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"⚠️ No GPU detected, running on CPU...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c0190c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Set some parameters\n",
    "IMG_HEIGHT, IMG_WIDTH = 40, 40\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100  # with early stopping\n",
    "NUM_CLASSES = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cec0b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id label\n",
      "0  21234.jpeg    14\n",
      "1  11574.jpeg     0\n",
      "2  21959.jpeg    16\n",
      "3  14462.jpeg    11\n",
      "4  02309.jpeg    13\n",
      "Found 17944 validated image filenames belonging to 20 classes.\n",
      "Found 4486 validated image filenames belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "# 2. Load labels\n",
    "labels_df = pd.read_csv('F:\\InfTech\\Prodotti\\Python\\Deep\\data\\labels.csv')  # <<== CHANGE path if needed\n",
    "labels_df['label'] = labels_df['label'].astype(str)  # Keras expects labels as strings for categorical\n",
    "\n",
    "# 3. Train/Validation split\n",
    "train_df, val_df = train_test_split(labels_df, test_size=0.2, stratify=labels_df['label'], random_state=42)\n",
    "\n",
    "# add 0 at the start if the id is less than 5 digits\n",
    "train_df['id'] = train_df['id'].apply(lambda x: str(x).zfill(5))\n",
    "val_df['id'] = val_df['id'].apply(lambda x: str(x).zfill(5))\n",
    "# add .jpeg at the end of the id\n",
    "train_df['id'] = train_df['id'].astype(str) + '.jpeg'\n",
    "val_df['id'] = val_df['id'].astype(str) + '.jpeg'\n",
    "\n",
    "# 4. Data generators with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    featurewise_center=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    zoom_range=0.2,\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "print(train_df.head())\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='./data/train_set',\n",
    "    x_col='id',\n",
    "    y_col='label',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory='./data/train_set',\n",
    "    x_col='id',\n",
    "    y_col='label',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False  # Important for validation data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fc92a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(128, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(units=512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "# 6. Compile the model\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 7. Callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aba986b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\camil\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\preprocessing\\image.py:1863: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "281/281 [==============================] - 71s 244ms/step - loss: 2.3930 - accuracy: 0.2420 - val_loss: 4.6491 - val_accuracy: 0.0633 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 1.9759 - accuracy: 0.3485 - val_loss: 2.8621 - val_accuracy: 0.1783 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 1.7944 - accuracy: 0.3960 - val_loss: 2.0235 - val_accuracy: 0.3359 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 1.6613 - accuracy: 0.4382 - val_loss: 2.2997 - val_accuracy: 0.2976 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 1.5459 - accuracy: 0.4765 - val_loss: 2.5854 - val_accuracy: 0.3074 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 1.4603 - accuracy: 0.5003 - val_loss: 1.9247 - val_accuracy: 0.4012 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 1.4015 - accuracy: 0.5247 - val_loss: 1.9439 - val_accuracy: 0.4004 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 1.3239 - accuracy: 0.5462 - val_loss: 1.6912 - val_accuracy: 0.4657 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 1.2743 - accuracy: 0.5668 - val_loss: 1.5560 - val_accuracy: 0.5029 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 1.2384 - accuracy: 0.5775 - val_loss: 1.4354 - val_accuracy: 0.5312 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 1.1788 - accuracy: 0.5967 - val_loss: 1.3592 - val_accuracy: 0.5524 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 1.1415 - accuracy: 0.6077 - val_loss: 1.6773 - val_accuracy: 0.4922 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 1.1018 - accuracy: 0.6249 - val_loss: 1.5785 - val_accuracy: 0.5223 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 1.0706 - accuracy: 0.6350 - val_loss: 1.4226 - val_accuracy: 0.5571 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 1.0380 - accuracy: 0.6451 - val_loss: 1.6999 - val_accuracy: 0.4971 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 11s 41ms/step - loss: 1.0019 - accuracy: 0.6599 - val_loss: 1.2587 - val_accuracy: 0.5965 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 11s 41ms/step - loss: 0.9795 - accuracy: 0.6668 - val_loss: 1.3454 - val_accuracy: 0.5849 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 11s 41ms/step - loss: 0.9452 - accuracy: 0.6786 - val_loss: 1.4810 - val_accuracy: 0.5571 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 11s 41ms/step - loss: 0.9351 - accuracy: 0.6803 - val_loss: 1.1071 - val_accuracy: 0.6320 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.8970 - accuracy: 0.6920 - val_loss: 1.5380 - val_accuracy: 0.5586 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 11s 41ms/step - loss: 0.8786 - accuracy: 0.6976 - val_loss: 1.1718 - val_accuracy: 0.6257 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.8635 - accuracy: 0.7045 - val_loss: 1.1613 - val_accuracy: 0.6286 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 12s 43ms/step - loss: 0.8482 - accuracy: 0.7089 - val_loss: 1.5069 - val_accuracy: 0.5490 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "280/281 [============================>.] - ETA: 0s - loss: 0.8302 - accuracy: 0.7133\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "281/281 [==============================] - 11s 39ms/step - loss: 0.8300 - accuracy: 0.7133 - val_loss: 1.2429 - val_accuracy: 0.6210 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 11s 39ms/step - loss: 0.7537 - accuracy: 0.7416 - val_loss: 1.2230 - val_accuracy: 0.6266 - lr: 5.0000e-05\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 11s 39ms/step - loss: 0.7394 - accuracy: 0.7450 - val_loss: 1.0442 - val_accuracy: 0.6632 - lr: 5.0000e-05\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 11s 39ms/step - loss: 0.7175 - accuracy: 0.7513 - val_loss: 0.9840 - val_accuracy: 0.6772 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 11s 39ms/step - loss: 0.7087 - accuracy: 0.7540 - val_loss: 1.2299 - val_accuracy: 0.6371 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 11s 39ms/step - loss: 0.6999 - accuracy: 0.7599 - val_loss: 1.2225 - val_accuracy: 0.6275 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 11s 39ms/step - loss: 0.6891 - accuracy: 0.7643 - val_loss: 1.0401 - val_accuracy: 0.6687 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 11s 39ms/step - loss: 0.6795 - accuracy: 0.7656 - val_loss: 1.0075 - val_accuracy: 0.6683 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - ETA: 0s - loss: 0.6701 - accuracy: 0.7701\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "281/281 [==============================] - 11s 39ms/step - loss: 0.6701 - accuracy: 0.7701 - val_loss: 1.0628 - val_accuracy: 0.6692 - lr: 5.0000e-05\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 12s 41ms/step - loss: 0.6361 - accuracy: 0.7762 - val_loss: 1.0063 - val_accuracy: 0.6821 - lr: 2.5000e-05\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 11s 41ms/step - loss: 0.6174 - accuracy: 0.7833 - val_loss: 1.0740 - val_accuracy: 0.6676 - lr: 2.5000e-05\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.6149 - accuracy: 0.7852 - val_loss: 0.9730 - val_accuracy: 0.6908 - lr: 2.5000e-05\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.5954 - accuracy: 0.7903 - val_loss: 1.0385 - val_accuracy: 0.6714 - lr: 2.5000e-05\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.6012 - accuracy: 0.7890 - val_loss: 1.0421 - val_accuracy: 0.6761 - lr: 2.5000e-05\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.5908 - accuracy: 0.7939 - val_loss: 1.1377 - val_accuracy: 0.6563 - lr: 2.5000e-05\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.5844 - accuracy: 0.7948 - val_loss: 1.1161 - val_accuracy: 0.6618 - lr: 2.5000e-05\n",
      "Epoch 40/100\n",
      "280/281 [============================>.] - ETA: 0s - loss: 0.5870 - accuracy: 0.7991\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.5871 - accuracy: 0.7989 - val_loss: 1.0595 - val_accuracy: 0.6696 - lr: 2.5000e-05\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.5638 - accuracy: 0.8034 - val_loss: 1.0339 - val_accuracy: 0.6759 - lr: 1.2500e-05\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.5678 - accuracy: 0.8004 - val_loss: 1.0289 - val_accuracy: 0.6866 - lr: 1.2500e-05\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.5595 - accuracy: 0.8020 - val_loss: 1.0390 - val_accuracy: 0.6770 - lr: 1.2500e-05\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.5564 - accuracy: 0.8047 - val_loss: 1.0398 - val_accuracy: 0.6799 - lr: 1.2500e-05\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - ETA: 0s - loss: 0.5588 - accuracy: 0.8066\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.5588 - accuracy: 0.8066 - val_loss: 1.0060 - val_accuracy: 0.6884 - lr: 1.2500e-05\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.5410 - accuracy: 0.8091 - val_loss: 1.0171 - val_accuracy: 0.6852 - lr: 6.2500e-06\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.5446 - accuracy: 0.8072 - val_loss: 1.0367 - val_accuracy: 0.6855 - lr: 6.2500e-06\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.5438 - accuracy: 0.8132 - val_loss: 1.0023 - val_accuracy: 0.6924 - lr: 6.2500e-06\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.5370 - accuracy: 0.8120 - val_loss: 1.0611 - val_accuracy: 0.6779 - lr: 6.2500e-06\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - ETA: 0s - loss: 0.5378 - accuracy: 0.8119\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.5378 - accuracy: 0.8119 - val_loss: 1.0187 - val_accuracy: 0.6857 - lr: 6.2500e-06\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.5354 - accuracy: 0.8116 - val_loss: 1.0160 - val_accuracy: 0.6888 - lr: 3.1250e-06\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.5348 - accuracy: 0.8131 - val_loss: 1.0276 - val_accuracy: 0.6872 - lr: 3.1250e-06\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.5253 - accuracy: 0.8168 - val_loss: 1.0112 - val_accuracy: 0.6919 - lr: 3.1250e-06\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.5270 - accuracy: 0.8175 - val_loss: 1.0397 - val_accuracy: 0.6839 - lr: 3.1250e-06\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - ETA: 0s - loss: 0.5275 - accuracy: 0.8128Restoring model weights from the end of the best epoch: 35.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "281/281 [==============================] - 11s 40ms/step - loss: 0.5275 - accuracy: 0.8128 - val_loss: 1.0534 - val_accuracy: 0.6812 - lr: 3.1250e-06\n",
      "Epoch 55: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 8. Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e013def3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 validated image filenames.\n",
      "63/63 [==============================] - 12s 185ms/step\n"
     ]
    }
   ],
   "source": [
    "# 9. Predict on test data\n",
    "import os\n",
    "test_filenames = os.listdir('./data/test_set')\n",
    "test_df = pd.DataFrame({'id': test_filenames})\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='./data/test_set',\n",
    "    x_col='id',\n",
    "    y_col = None,\n",
    "    class_mode=None,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False  # Important for validation data\n",
    "    \n",
    ")\n",
    "\n",
    "predictions = model.predict(test_generator, verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "353e1bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1, 10: 2, 11: 3, 12: 4, 13: 5, 14: 6, 15: 7, 16: 8, 17: 9, 18: 10, 19: 11, 2: 12, 3: 13, 4: 14, 5: 15, 6: 16, 7: 17, 8: 18, 9: 19}\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_df['label'].unique()\n",
    "train_class_mapping = {int(label): idx for idx, label in enumerate(sorted(train_labels))}\n",
    "print(train_class_mapping)\n",
    "\n",
    "# Convert predicted class indices to actual labels using the class mapping\n",
    "predicted_labels = [list(train_class_mapping.keys())[pred] for pred in predicted_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fac62f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Save submission file\n",
    "submission = pd.DataFrame({'id': test_df['id'], 'label': predicted_labels})\n",
    "submission['id'] = submission['id'].apply(lambda x: int(os.path.splitext(x)[0]))  # remove .png if necessary\n",
    "submission.sort_values('id', inplace=True)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
